{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Filter and Create Sample Sets",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIhBJrK1yWbu"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "!pip install -q -U pandas\n",
        "import pandas as pd\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThtAOTmoyk1L",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "5b441e3c-da36-4497-f5d3-9fc8aa3bfb95"
      },
      "source": [
        "try:\n",
        "  df = pd.read_csv('Data_Entry_2017.csv')\n",
        "except:\n",
        "  uploaded = files.upload()\n",
        "  df = pd.read_csv(io.BytesIO(uploaded['Data_Entry_2017.csv']))\n",
        "\n",
        "df.head(n=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5a808693-6693-48dc-b703-e57cc62f3fbe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5a808693-6693-48dc-b703-e57cc62f3fbe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Data_Entry_2017.csv to Data_Entry_2017.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Finding Labels</th>\n",
              "      <th>Follow-up #</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Gender</th>\n",
              "      <th>View Position</th>\n",
              "      <th>OriginalImage[Width</th>\n",
              "      <th>Height]</th>\n",
              "      <th>OriginalImagePixelSpacing[x</th>\n",
              "      <th>y]</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000001_000.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2682</td>\n",
              "      <td>2749</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.143</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Image Index Finding Labels  ...     y]  Unnamed: 11\n",
              "0  00000001_000.png   Cardiomegaly  ...  0.143          NaN\n",
              "\n",
              "[1 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHJGjtkm1B7V"
      },
      "source": [
        "## Pick Patients who have at least 3 followups (indexing from 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmbYdP-t1IPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a622b61-2acc-4293-cf65-cbf6656db54d"
      },
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "df_updated_followups = df.groupby('Patient ID').filter(lambda x : len(x)>2)\n",
        "print(\"Filter 1\")\n",
        "print(\"Patients with at least 3 follow-ups: \"+ str(df_updated_followups.groupby('Patient ID').ngroups))\n",
        "print(\"-----------------------------------------------\")\n",
        "'''\n",
        "remove patients that have followups with different view positions.\n",
        "if patient 1 has PA and AP images then remove patient 1\n",
        "then save filtered data into a csv named df_updated_view_position.csv\n",
        "'''\n",
        "df_updated_view_postion = df_updated_followups[df_updated_followups.groupby(\"Patient ID\")[\"View Position\"].transform('nunique')<=1]\n",
        "df_updated_view_postion = df_updated_view_postion.reset_index()\n",
        "print(\"Filter 2\")\n",
        "print(\"Patients homogenous view positions:\" +str(df_updated_view_postion.groupby('Patient ID').ngroups))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filter 1\n",
            "Patients with at least 3 follow-ups: 9189\n",
            "-----------------------------------------------\n",
            "Filter 2\n",
            "Patients homogenous view positions:2992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDOQRRXkNOy-"
      },
      "source": [
        "#### Splitting rows if more than 1 finding label for follow up 2 and above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS_x8CScLe8L"
      },
      "source": [
        "import csv ,os\n",
        "\n",
        "df_updated_view_postion.to_csv('df_updated_view_postion.csv',na_rep='=NA()')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rke8BBVLXmUJ"
      },
      "source": [
        "**Example 1**\n",
        "\n",
        "        Sample set should consist of 3 follow-ups. In each sample set we look \n",
        "        at the 3rd follow-up. If Followup 3 has more than 1 disease then we \n",
        "        will create a new sample containing identical follow-ups 0 and 1 but \n",
        "        there will be a new third follow-up depending on the disease.\n",
        "\n",
        "        example: \n",
        "          00000013_023.png , Infiltration|Mass|Pneumothorax        Follow-up 0, Patient 13\n",
        "          00000013_024.png , Mass                                  Follow-up 1 , Patient 13\n",
        "          00000013_025.png , Cardiomegaly|Infiltration             Follow-up 2 , Patient 13\n",
        "\n",
        "        result :\n",
        "          00000013_023.png , Infiltration|Mass|Pneumothorax        Follow-up 0, Patient 13, Sample # 1\n",
        "          00000013_024.png , Mass                                  Follow-up 1 , Patient 13, Sample # 1\n",
        "          00000013_025.png , Cardiomegaly                          Follow-up 2,Patient 13, Sample # 1\n",
        "\n",
        "          00000013_023.png , Infiltration|Mass|Pneumothorax        Follow-up 0, Patient 13, Sample # 2\n",
        "          00000013_024.png , Mass                                  Follow-up 1,Patient 13, Sample # 2\n",
        "          00000013_025.png , Infiltration                          Follow-up 2,Patient 13, Sample # 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpT6PxBN2NWl"
      },
      "source": [
        "# Read in filtered data csv \n",
        "try:\n",
        "  new_df = pd.read_csv('df_updated_view_postion.csv')\n",
        "except:\n",
        "  uploaded = files.upload()\n",
        "  new_df = pd.read_csv(io.BytesIO(uploaded['df_updated_view_postion.csv']))\n",
        "\n",
        "# remove index columns from csv\n",
        "new_df = new_df.iloc[:,2:13]\n",
        "\n",
        "# list of diseases to search through\n",
        "find_labels=[\"Atelectasis\",\"Consolidation\",\"Infiltration\",\"Pneumothorax\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Effusion\",\"Pneumonia\",\"Pleural_Thickening\",\"Cardiomegaly\",\"Nodule\",\"Mass\",\"Hernia\"]\n",
        "label = {}\n",
        "\n",
        "# get the field names to write to new csv. Add Sample # column\n",
        "fieldnames = new_df.columns.tolist()\n",
        "fieldnames.append(\"Sample #\")\n",
        "\n",
        "# keeping track of first follow-up in sample\n",
        "pointer_followup_init= 0\n",
        "# keeping track of third follow-up in sample\n",
        "pointer_followup_final= 0\n",
        "\n",
        "# Sample set will contain 3 followups\n",
        "sample_set = []\n",
        "\n",
        "# keep track of sample number\n",
        "sample_number=  0\n",
        "\n",
        "# open new csv to write to named df_updated_finding_labels.csv\n",
        "with open('df_updated_finding_labels.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=',')\n",
        "\n",
        "  # write the header names as first row in csv\n",
        "  writer.writerow(fieldnames)\n",
        "\n",
        "  for index, row in new_df.iterrows():\n",
        "    # Look ahead logic to skip to relevant rows when sample sets for patient\n",
        "    # have been written to new csv\n",
        "    if index > 0 and index != pointer_followup_init:\n",
        "      continue\n",
        "\n",
        "    # set new sample set for upon seeing a new patient\n",
        "    # and initialize the follow-up 0 and 2 index\n",
        "    if row['Follow-up #'] == 0:\n",
        "      pointer_followup_init = index\n",
        "      pointer_followup_final= pointer_followup_init + 2\n",
        "\n",
        "    # sample_set will hold the first two follow-ups within a sample set\n",
        "    sample_set.append(new_df.iloc[pointer_followup_init,:].tolist())\n",
        "    sample_set[0].append(sample_number)\n",
        "\n",
        "    sample_set.append(new_df.iloc[pointer_followup_init+1,:].tolist())\n",
        "    sample_set[1].append(sample_number)\n",
        "\n",
        "    # check followup 2 in sample set\n",
        "    # if it contains 1 disease then add it to sample set and write the set to csv\n",
        "    if '|'  not in new_df.iloc[pointer_followup_final,1]:\n",
        "        sample_set.append(new_df.iloc[pointer_followup_final,:].tolist())\n",
        "        sample_set[2].append(sample_number)\n",
        "        sample_number += 1\n",
        "        for x1_row in sample_set:\n",
        "          writer.writerow(x1_row)\n",
        "        sample_set.clear()\n",
        "    # otherwise look for diseases in follow 2 in sample set\n",
        "    else: \n",
        "      for disease in find_labels:\n",
        "        ''' \n",
        "        Steps\n",
        "          1) Add individual disease into sample set and write to csv\n",
        "          2) Remove follow-up 2 from sample set and rewrite the new disease\n",
        "          3) Write new sample set while maintaining follow-up 0,follow-up 1\n",
        "             but adding new follow-up 2 into csv\n",
        "          4) Do the same till all the diseases are extracted from original follow-up 2\n",
        "             that contains multiple diseases\n",
        "          Refer to Example 1\n",
        "        '''\n",
        "        #  check diseases in follow-up 2 'Finding Labels' column \n",
        "        if disease in new_df.iloc[pointer_followup_final,1]: \n",
        "          temp_finding_label = new_df.iloc[pointer_followup_final,1]\n",
        "          new_df.iloc[pointer_followup_final,1] = disease\n",
        "          sample_set.append(new_df.iloc[pointer_followup_final,:].tolist())\n",
        "          new_df.iloc[pointer_followup_final,1] = temp_finding_label\n",
        "          sample_set[2].append(sample_number)\n",
        "          for x_row in sample_set:\n",
        "            # delete sample number of followup within a set\n",
        "            if not isinstance(x_row,list):\n",
        "              x_row = list(x_row)\n",
        "            # keep track of sample number within a set\n",
        "            x_row[-1] = sample_number\n",
        "            writer.writerow(x_row)\n",
        "          \n",
        "          del sample_set[2]\n",
        "          sample_number += 1\n",
        "      sample_set=[]\n",
        "    # keep track of end of dataframe and exit when end is reached\n",
        "    if pointer_followup_final + 1 >= new_df.shape[0]:\n",
        "      break\n",
        "      \n",
        "    # update follow-up init pointer which looks ahead for new\n",
        "    # encountered patient using value in 'Follow-up #' column\n",
        "    if new_df.iloc[pointer_followup_final+1,2] == 0:\n",
        "      pointer_followup_init = pointer_followup_final+1\n",
        "    elif new_df.iloc[pointer_followup_final+1,2] > 0:\n",
        "      pointer_followup_init += 1\n",
        "      pointer_followup_final += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EO-dugGBH60"
      },
      "source": [
        "## Create two different datasets based on view position"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9qQuNlJBTkx"
      },
      "source": [
        "### PA Position"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omnt58Dq6gIo"
      },
      "source": [
        "'''\n",
        "  Read in csv with newly created sample sets \n",
        "  Find all the patients with PA View Positions in the Follow-ups\n",
        "  Rewrite new sample numbers for filtered data \n",
        "  Then write results in df_PA.csv\n",
        "'''\n",
        "\n",
        "try:\n",
        "  df_updated_finding_labels = pd.read_csv('df_updated_finding_labels.csv')\n",
        "except:\n",
        "  uploaded = files.upload()\n",
        "  df_updated_finding_labels = pd.read_csv(io.BytesIO(uploaded['df_updated_finding_labels.csv']))\n",
        "\n",
        "df_PA = df_updated_finding_labels.loc[df_updated_finding_labels['View Position']==\"PA\",:]\n",
        "df_PA = df_PA.iloc[:,0:11]\n",
        "\n",
        "\n",
        "sample_num = 1\n",
        "count = 0\n",
        "fieldnames = df_PA.columns.tolist()\n",
        "fieldnames.append('Sample #')\n",
        "with open('df_PA.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=',')\n",
        "  # print(fieldnames)\n",
        "  writer.writerow(fieldnames)\n",
        "  for index, row in df_PA.iterrows():\n",
        "    \n",
        "    if count == 3:\n",
        "      sample_num += 1\n",
        "      count = 0\n",
        "    count += 1\n",
        "    row = row.tolist()\n",
        "    row.append(sample_num)\n",
        "    writer.writerow(row)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS8rnqUOOr9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d1886d-90fd-4cad-a4cf-3584c2853417"
      },
      "source": [
        "print(\"Number Unique Patients in PA dataset: \" + str(df_PA.groupby('Patient ID').ngroups))\n",
        "print(\"Number of Samples in PA dataset: \"+str(int(df_PA.shape[0]/3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Unique Patients in PA dataset: 2552\n",
            "Number of Samples in PA dataset: 8114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Pv8_ZwBvfR"
      },
      "source": [
        "### AP Position"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vIU1vW1rsux"
      },
      "source": [
        "'''\n",
        "  Read in csv with newly created sample sets \n",
        "  Find all the patients with AP View Positions in the Follow-ups\n",
        "  Rewrite new sample numbers for filtered data \n",
        "  Then write results in df_AP.csv\n",
        "'''\n",
        "try:\n",
        "  df_updated_finding_labels = pd.read_csv('df_updated_finding_labels.csv')\n",
        "except:\n",
        "  uploaded = files.upload()\n",
        "  df_updated_finding_labels = pd.read_csv(io.BytesIO(uploaded['df_updated_finding_labels.csv']))\n",
        "\n",
        "df_AP = df_updated_finding_labels.loc[df_updated_finding_labels['View Position']==\"AP\",:]\n",
        "df_AP = df_AP.iloc[:,0:11]\n",
        "\n",
        "\n",
        "sample_num = 1\n",
        "count = 0\n",
        "fieldnames = df_AP.columns.tolist()\n",
        "fieldnames.append('Sample #')\n",
        "with open('df_AP.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=',')\n",
        "  # print(fieldnames)\n",
        "  writer.writerow(fieldnames)\n",
        "  for index, row in df_AP.iterrows():\n",
        "    \n",
        "    if count == 3:\n",
        "      sample_num += 1\n",
        "      count = 0\n",
        "    count += 1\n",
        "    row = row.tolist()\n",
        "    row.append(sample_num)\n",
        "    writer.writerow(row)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0u-cPaNDen3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e4e421a-04be-45ec-9911-a6273b76f530"
      },
      "source": [
        "print(\"Number Unique Patients in AP dataset: \" + str(df_AP.groupby('Patient ID').ngroups))\n",
        "print(\"Number of Samples in AP dataset: \"+str(int(df_AP.shape[0]/3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Unique Patients in AP dataset: 440\n",
            "Number of Samples in AP dataset: 3905\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}