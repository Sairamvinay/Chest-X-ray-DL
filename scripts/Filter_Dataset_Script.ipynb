{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Filter_Dataset_script",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIhBJrK1yWbu"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "!pip install -q -U pandas\n",
        "import pandas as pd\n",
        "import io"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThtAOTmoyk1L",
        "outputId": "05b0b404-84e9-44eb-a97c-289141431123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "try:\n",
        "  df = pd.read_csv('Data_Entry_2017.csv')\n",
        "except:\n",
        "  uploaded = files.upload()\n",
        "  df = pd.read_csv(io.BytesIO(uploaded['Data_Entry_2017.csv']))\n",
        "\n",
        "df.head(n=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Finding Labels</th>\n",
              "      <th>Follow-up #</th>\n",
              "      <th>Patient ID</th>\n",
              "      <th>Patient Age</th>\n",
              "      <th>Patient Gender</th>\n",
              "      <th>View Position</th>\n",
              "      <th>OriginalImage[Width</th>\n",
              "      <th>Height]</th>\n",
              "      <th>OriginalImagePixelSpacing[x</th>\n",
              "      <th>y]</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000001_000.png</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "      <td>M</td>\n",
              "      <td>PA</td>\n",
              "      <td>2682</td>\n",
              "      <td>2749</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.143</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Image Index Finding Labels  Follow-up #  Patient ID  Patient Age  \\\n",
              "0  00000001_000.png   Cardiomegaly            0           1           58   \n",
              "\n",
              "  Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
              "0              M            PA                 2682     2749   \n",
              "\n",
              "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n",
              "0                        0.143  0.143          NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHJGjtkm1B7V"
      },
      "source": [
        "## Pick Patients who have at least 3 followups (indexing from 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmbYdP-t1IPn",
        "outputId": "dccc3c80-dccd-4466-a111-c616d51015a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "df_updated_followups = df.groupby('Patient ID').filter(lambda x : len(x)>2)\n",
        "\n",
        "\n",
        "'''\n",
        "remove patients that have followups with different view positions.\n",
        "if patient 1 has PA and AP images then remove patient 1\n",
        "then save filtered data into a csv named df_updated_view_position.csv\n",
        "'''\n",
        "df_updated_view_postion = df_updated_followups[df_updated_followups.groupby(\"Patient ID\")[\"View Position\"].transform('nunique')<=1]\n",
        "df_updated_view_postion = df_updated_view_postion.reset_index()\n",
        "print(\"Number of unique patients :\" +str(df_updated_view_postion.groupby('Patient ID').ngroups))\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique patients :2992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDOQRRXkNOy-"
      },
      "source": [
        "#### Splitting rows if more than 1 finding label for follow up 2 and above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS_x8CScLe8L"
      },
      "source": [
        "import csv ,os\n",
        "\n",
        "df_updated_view_postion.to_csv('df_updated_view_postion.csv',na_rep='=NA()')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rke8BBVLXmUJ"
      },
      "source": [
        "**Example 1**\n",
        "\n",
        "        Sample set should consist of 3 follow-ups. In each sample set we look \n",
        "        at the 3rd follow-up. If Followup 3 has more than 1 disease then we \n",
        "        will create a new sample containing identical follow-ups 0 and 1 but \n",
        "        there will be a new third follow-up depending on the disease.\n",
        "\n",
        "        example: \n",
        "          00000013_023.png , Infiltration|Mass|Pneumothorax        Follow-up 0, Patient 13\n",
        "          00000013_024.png , Mass                                  Follow-up 1 , Patient 13\n",
        "          00000013_025.png , Cardiomegaly|Infiltration             Follow-up 2 , Patient 13\n",
        "\n",
        "        result :\n",
        "          00000013_023.png , Infiltration|Mass|Pneumothorax        Follow-up 0, Patient 13, Sample # 1\n",
        "          00000013_024.png , Mass                                  Follow-up 1 , Patient 13, Sample # 1\n",
        "          00000013_025.png , Cardiomegaly                          Follow-up 2,Patient 13, Sample # 1\n",
        "\n",
        "          00000013_023.png , Infiltration|Mass|Pneumothorax        Follow-up 0, Patient 13, Sample # 2\n",
        "          00000013_024.png , Mass                                  Follow-up 1,Patient 13, Sample # 2\n",
        "          00000013_025.png , Infiltration                          Follow-up 2,Patient 13, Sample # 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpT6PxBN2NWl"
      },
      "source": [
        "# Read in filtered data csv \n",
        "try:\n",
        "  new_df = pd.read_csv('df_updated_view_postion.csv')\n",
        "except:\n",
        "  uploaded = files.upload()\n",
        "  new_df = pd.read_csv(io.BytesIO(uploaded['df_updated_view_postion.csv']))\n",
        "\n",
        "# remove index columns from csv\n",
        "new_df = new_df.iloc[:,2:13]\n",
        "\n",
        "# list of diseases to search through\n",
        "find_labels=[\"Atelectasis\",\"Consolidation\",\"Infiltration\",\"Pneumothorax\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Effusion\",\"Pneumonia\",\"Pleural_Thickening\",\"Cardiomegaly\",\"Nodule\",\"Mass\",\"Hernia\"]\n",
        "label = {}\n",
        "\n",
        "# get the field names to write to new csv. Add Sample # column\n",
        "fieldnames = new_df.columns.tolist()\n",
        "fieldnames.append(\"Sample #\")\n",
        "\n",
        "# keeping track of first follow-up in sample\n",
        "pointer_followup_init= 0\n",
        "# keeping track of third follow-up in sample\n",
        "pointer_followup_final= 0\n",
        "\n",
        "# Sample set will contain 3 followups\n",
        "sample_set = []\n",
        "\n",
        "# keep track of sample number\n",
        "sample_number=  0\n",
        "\n",
        "# open new csv to write to named df_updated_finding_labels.csv\n",
        "with open('df_updated_finding_labels.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=',')\n",
        "\n",
        "  # write the header names as first row in csv\n",
        "  writer.writerow(fieldnames)\n",
        "\n",
        "  for index, row in new_df.iterrows():\n",
        "    # Look ahead logic to skip to relevant rows when sample sets for patient\n",
        "    # have been written to new csv\n",
        "    if index > 0 and index != pointer_followup_init:\n",
        "      continue\n",
        "\n",
        "    # set new sample set for upon seeing a new patient\n",
        "    # and initialize the follow-up 0 and 2 index\n",
        "    if row['Follow-up #'] == 0:\n",
        "      pointer_followup_init = index\n",
        "      pointer_followup_final= pointer_followup_init + 2\n",
        "\n",
        "    # sample_set will hold the first two follow-ups within a sample set\n",
        "    sample_set.append(new_df.iloc[pointer_followup_init,:].tolist())\n",
        "    sample_set[0].append(sample_number)\n",
        "\n",
        "    sample_set.append(new_df.iloc[pointer_followup_init+1,:].tolist())\n",
        "    sample_set[1].append(sample_number)\n",
        "\n",
        "    # check followup 2 in sample set\n",
        "    # if it contains 1 disease then add it to sample set and write the set to csv\n",
        "    if '|'  not in new_df.iloc[pointer_followup_final,1]:\n",
        "        sample_set.append(new_df.iloc[pointer_followup_final,:].tolist())\n",
        "        sample_set[2].append(sample_number)\n",
        "        sample_number += 1\n",
        "        for x1_row in sample_set:\n",
        "          writer.writerow(x1_row)\n",
        "        sample_set.clear()\n",
        "    # otherwise look for diseases in follow 2 in sample set\n",
        "    else: \n",
        "      for disease in find_labels:\n",
        "        ''' \n",
        "        Steps\n",
        "          1) Add individual disease into sample set and write to csv\n",
        "          2) Remove follow-up 2 from sample set and rewrite the new disease\n",
        "          3) Write new sample set while maintaining follow-up 0,follow-up 1\n",
        "             but adding new follow-up 2 into csv\n",
        "          4) Do the same till all the diseases are extracted from original follow-up 2\n",
        "             that contains multiple diseases\n",
        "          Refer to Example 1\n",
        "        '''\n",
        "        #  check diseases in follow-up 2 'Finding Labels' column \n",
        "        if disease in new_df.iloc[pointer_followup_final,1]: \n",
        "          temp_finding_label = new_df.iloc[pointer_followup_final,1]\n",
        "          new_df.iloc[pointer_followup_final,1] = disease\n",
        "          sample_set.append(new_df.iloc[pointer_followup_final,:].tolist())\n",
        "          new_df.iloc[pointer_followup_final,1] = temp_finding_label\n",
        "          sample_set[2].append(sample_number)\n",
        "          for x_row in sample_set:\n",
        "            # delete sample number of followup within a set\n",
        "            if not isinstance(x_row,list):\n",
        "              x_row = list(x_row)\n",
        "            # keep track of sample number within a set\n",
        "            x_row[-1] = sample_number\n",
        "            writer.writerow(x_row)\n",
        "          \n",
        "          del sample_set[2]\n",
        "          sample_number += 1\n",
        "      sample_set=[]\n",
        "    # keep track of end of dataframe and exit when end is reached\n",
        "    if pointer_followup_final + 1 >= new_df.shape[0]:\n",
        "      break\n",
        "      \n",
        "    # update follow-up init pointer which looks ahead for new\n",
        "    # encountered patient using value in 'Follow-up #' column\n",
        "    if new_df.iloc[pointer_followup_final+1,2] == 0:\n",
        "      pointer_followup_init = pointer_followup_final+1\n",
        "    elif new_df.iloc[pointer_followup_final+1,2] > 0:\n",
        "      pointer_followup_init += 1\n",
        "      pointer_followup_final += 1\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EO-dugGBH60"
      },
      "source": [
        "## Create two different datasets based on view position"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9qQuNlJBTkx"
      },
      "source": [
        "### PA Position"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omnt58Dq6gIo"
      },
      "source": [
        "'''\n",
        "  Read in csv with newly created sample sets \n",
        "  Find all the patients with PA View Positions in the Follow-ups\n",
        "  Rewrite new sample numbers for filtered data \n",
        "  Then write results in df_PA.csv\n",
        "'''\n",
        "\n",
        "try:\n",
        "  df_updated_finding_labels = pd.read_csv('df_updated_finding_labels.csv')\n",
        "except:\n",
        "  uploaded = files.upload()\n",
        "  df_updated_finding_labels = pd.read_csv(io.BytesIO(uploaded['df_updated_finding_labels.csv']))\n",
        "\n",
        "df_PA = df_updated_finding_labels.loc[df_updated_finding_labels['View Position']==\"PA\",:]\n",
        "df_PA = df_PA.iloc[:,0:11]\n",
        "\n",
        "\n",
        "sample_num = 1\n",
        "count = 0\n",
        "fieldnames = df_PA.columns.tolist()\n",
        "fieldnames.append('Sample #')\n",
        "with open('df_PA.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=',')\n",
        "  # print(fieldnames)\n",
        "  writer.writerow(fieldnames)\n",
        "  for index, row in df_PA.iterrows():\n",
        "    \n",
        "    if count == 3:\n",
        "      sample_num += 1\n",
        "      count = 0\n",
        "    count += 1\n",
        "    row = row.tolist()\n",
        "    row.append(sample_num)\n",
        "    writer.writerow(row)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS8rnqUOOr9f",
        "outputId": "08d1886d-90fd-4cad-a4cf-3584c2853417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Number Unique Patients in PA dataset: \" + str(df_PA.groupby('Patient ID').ngroups))\n",
        "print(\"Number of Samples in PA dataset: \"+str(int(df_PA.shape[0]/3)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Unique Patients in PA dataset: 2552\n",
            "Number of Samples in PA dataset: 8114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15Pv8_ZwBvfR"
      },
      "source": [
        "### AP Position"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vIU1vW1rsux"
      },
      "source": [
        "'''\n",
        "  Read in csv with newly created sample sets \n",
        "  Find all the patients with AP View Positions in the Follow-ups\n",
        "  Rewrite new sample numbers for filtered data \n",
        "  Then write results in df_AP.csv\n",
        "'''\n",
        "try:\n",
        "  df_updated_finding_labels = pd.read_csv('df_updated_finding_labels.csv')\n",
        "except:\n",
        "  uploaded = files.upload()\n",
        "  df_updated_finding_labels = pd.read_csv(io.BytesIO(uploaded['df_updated_finding_labels.csv']))\n",
        "\n",
        "df_AP = df_updated_finding_labels.loc[df_updated_finding_labels['View Position']==\"AP\",:]\n",
        "df_AP = df_AP.iloc[:,0:11]\n",
        "\n",
        "\n",
        "sample_num = 1\n",
        "count = 0\n",
        "fieldnames = df_AP.columns.tolist()\n",
        "fieldnames.append('Sample #')\n",
        "with open('df_AP.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile, delimiter=',')\n",
        "  # print(fieldnames)\n",
        "  writer.writerow(fieldnames)\n",
        "  for index, row in df_AP.iterrows():\n",
        "    \n",
        "    if count == 3:\n",
        "      sample_num += 1\n",
        "      count = 0\n",
        "    count += 1\n",
        "    row = row.tolist()\n",
        "    row.append(sample_num)\n",
        "    writer.writerow(row)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0u-cPaNDen3",
        "outputId": "4e4e421a-04be-45ec-9911-a6273b76f530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Number Unique Patients in AP dataset: \" + str(df_AP.groupby('Patient ID').ngroups))\n",
        "print(\"Number of Samples in AP dataset: \"+str(int(df_AP.shape[0]/3)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Unique Patients in AP dataset: 440\n",
            "Number of Samples in AP dataset: 3905\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}